{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from batchNormalization import BatchNormalization\n",
    "from affine import Affine\n",
    "from relu import Relu\n",
    "from dropout import Dropout\n",
    "from identityWithLoss import IdentityWithLoss\n",
    "from model import Model\n",
    "from optimizer import SGD, Momentum, AdaGrad, RMSprop, Adam\n",
    "from trainer import Trainer\n",
    "from util import scale\n",
    "from metrics import Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = {'CRIM':float, 'ZN':float, 'INDUS':float, 'CHAS':int, 'NOX':float, 'RM':float, 'AGE':float, 'DIS':float, 'RAD':object, 'TAX':int, 'PTRATIO':float, 'B':float, 'LSTAT':float, 'TARGET':float}\n",
    "df = pd.read_csv('./housing.data', header=None, sep='\\s+', na_values='na', names=columns.keys(), dtype=columns)\n",
    "y = df['TARGET']\n",
    "tp = df[['CHAS','RAD']]\n",
    "df = df.drop(['TARGET','CHAS','RAD'], axis=1)\n",
    "df = (df - df.mean()) / df.std(ddof=0)\n",
    "tp = pd.get_dummies(tp, dummy_na=False, columns=['RAD'])\n",
    "df = pd.concat([df,tp], axis=1, sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=1, train_size=0.7, random_state=0)\n",
    "train_idx, test_idx = next(ss.split(df, y))\n",
    "df = df.to_numpy()\n",
    "y = y.to_numpy()\n",
    "x_train, x_test, t_train, t_test = df[train_idx], df[test_idx], y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習\n",
    "m = Model()\n",
    "m.append(Affine(scale(21) * np.random.randn(21, 100), np.zeros(100)))\n",
    "m.append(BatchNormalization(np.ones(100), np.zeros(100)))\n",
    "m.append(Relu())\n",
    "m.append(Dropout())\n",
    "m.append(Affine(scale(100) * np.random.randn(100, 100), np.zeros(100)))\n",
    "m.append(BatchNormalization(np.ones(100), np.zeros(100)))\n",
    "m.append(Relu())\n",
    "m.append(Dropout())\n",
    "m.append(Affine(scale(100) * np.random.randn(100, 1), np.zeros(1)))\n",
    "m.append_loss(IdentityWithLoss())\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainer(m, SGD(lr=0.1), Factory.create(Factory.MTYPE.R2))\n",
    "t.fit(x_train, t_train, 30, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テスト\n",
    "for i in range(len(x_test)):\n",
    "    y = m.predict(x_test[[i]])\n",
    "    loss, prd = m.loss.forward(y, t_test[[i]])\n",
    "    t.metrics.add_metrics(loss, t_test[i], prd)\n",
    "t.metrics.get_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
